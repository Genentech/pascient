{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edcbbc4-e75e-4e63-a954-454c7bce3ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Optional\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from lightning import LightningDataModule\n",
    "\n",
    "sys.path.insert(0, \"../\") #load the cellm outside of notebooks\n",
    "sys.path.insert(0, \"../reproduce/\") #load the rep_utils outside of notebooks\n",
    "\n",
    "from cellm.data.data_scimilarity_gred import SampleCellsDataModule_disease, scDataset_disease\n",
    "\n",
    "# from cellm.data.data_structures import CellSample\n",
    "import pickle\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import torch\n",
    "import json\n",
    "import sklearn\n",
    "\n",
    "from captum.attr import IntegratedGradients\n",
    "\n",
    "import scipy.stats\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report #1e-3, best save\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import scanpy as sc\n",
    "\n",
    "def most_frequent_per_row(array):\n",
    "    most_frequent_values = []\n",
    "    for row in array:\n",
    "        counts = np.bincount(row)\n",
    "        most_frequent = np.argmax(counts)\n",
    "        most_frequent_values.append(most_frequent)\n",
    "    return np.array(most_frequent_values)\n",
    "\n",
    "from cellm.components.cell_to_cell import CellToCellPytorchTransformer\n",
    "from cellm.components.cell_to_output import CellToOutputMLP\n",
    "from cellm.components.gene_to_cell import GeneToCellLinear\n",
    "from cellm.components.masking import Masking\n",
    "from cellm.data.data_structures import CellSample\n",
    "from rep_exp_utils import CellClassifyModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2edfcf-e108-4b8a-8a50-6149bb1b819c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1score_list = []\n",
    "finalauroc_list = []\n",
    "class_model = CellClassifyModel.load_from_checkpoint(\"./disease_class/disease2classlr1e3wd1e4batch32epoch50_weightaverage_dim1-epoch=36-val_accuracy=0.82.ckpt\", num_genes=28231, masking_strategy=None, attn = 'linear_attn')\n",
    "\n",
    "ig = IntegratedGradients(class_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c01d112-4350-4941-adad-be4b3f21eec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(\"./combined_4dataset_processed_data.h5ad\")\n",
    "gene_list = pd.read_csv(\"/gstore/data/omni/scdb/cleaned_h5ads/gene_order.tsv\", header=None)\n",
    "gene_list = gene_list[0].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7942ef3-ecda-411a-80a9-8075903033e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_new = sc.AnnData(np.zeros((1,len(gene_list))))\n",
    "adata_new.var_names = gene_list\n",
    "adata_c = sc.concat([adata_new, adata], join='outer', label='batch_new')\n",
    "\n",
    "adata_c_f = adata_c[adata_c.obs['batch_new'] == '1']\n",
    "adata_c_f = adata_c_f[:, gene_list]\n",
    "adata_c_f.obs['sampleID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b015b92a-b241-4a31-8e26-10ee8ef59749",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    sample_data_list = []\n",
    "    dis_label = []\n",
    "    with torch.no_grad():\n",
    "        for item in adata_c_f.obs['sampleID'].unique():\n",
    "            adata_s = adata_c_f[adata_c_f.obs['sampleID'] == item]\n",
    "            input_data = adata_s.X.toarray().reshape(1,  adata_s.X.shape[0], adata_s.X.shape[1])\n",
    "            query = torch.FloatTensor(input_data).cuda()\n",
    "            sample_data,probs = class_model.obtain_annotation_directly(query)\n",
    "            sample_data_list.append(probs.cpu().numpy())\n",
    "            dis_label.append(adata_s.obs['condition'][0])\n",
    "else:\n",
    "    sample_data_list = []\n",
    "    dis_label = []\n",
    "    with torch.no_grad():\n",
    "        for item in adata_c_f.obs['sampleID'].unique():\n",
    "            adata_s = adata_c_f[adata_c_f.obs['sampleID'] == item]\n",
    "            input_data = adata_s.X.toarray().reshape(1,  adata_s.X.shape[0], adata_s.X.shape[1])\n",
    "            query = torch.FloatTensor(input_data)\n",
    "            sample_data,probs = class_model.obtain_annotation_directly(query)\n",
    "            sample_data_list.append(probs.cpu().numpy())\n",
    "            dis_label.append(adata_s.obs['condition'][0])\n",
    "\n",
    "healthy_average = []\n",
    "disease_average = []\n",
    "for i,j in zip(sample_data_list,dis_label):\n",
    "    if j == 'Mild':\n",
    "        healthy_average.append(i[0][1])\n",
    "    else:\n",
    "        disease_average.append(i[0][1])\n",
    "\n",
    "\n",
    "print(scipy.stats.ranksums(healthy_average, disease_average, alternative='less'))\n",
    "\n",
    "\n",
    "df1 = pd.DataFrame({'Mild':healthy_average})\n",
    "df2 = pd.DataFrame({'Severe':disease_average})\n",
    "\n",
    "\n",
    "\n",
    "df = pd.concat([df1, df2])\n",
    "\n",
    "\n",
    "df.boxplot(figsize=(4,4), fontsize=15)\n",
    "plt.ylabel('Probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9504f798-2db3-485f-b7ec-8fa6212a28bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    sample_data_list = []\n",
    "    dis_label = []\n",
    "    with torch.no_grad():\n",
    "        for item in adata_c_f.obs['sampleID'].unique():\n",
    "            adata_s = adata_c_f[adata_c_f.obs['sampleID'] == item]\n",
    "            input_data = adata_s.X.toarray().reshape(1,  adata_s.X.shape[0], adata_s.X.shape[1])\n",
    "            query = torch.FloatTensor(input_data).cuda()\n",
    "            sample_data = class_model.obtain_embeddings_zs(query)\n",
    "            sample_data_list.append(sample_data.cpu().numpy())\n",
    "            dis_label.append(adata_s.obs['condition'][0])\n",
    "else:\n",
    "    sample_data_list = []\n",
    "    dis_label = []\n",
    "    with torch.no_grad():\n",
    "        for item in adata_c_f.obs['sampleID'].unique():\n",
    "            adata_s = adata_c_f[adata_c_f.obs['sampleID'] == item]\n",
    "            input_data = adata_s.X.toarray().reshape(1,  adata_s.X.shape[0], adata_s.X.shape[1])\n",
    "            query = torch.FloatTensor(input_data)\n",
    "            sample_data = class_model.obtain_embeddings_zs(query)\n",
    "            sample_data_list.append(sample_data.cpu().numpy())\n",
    "            dis_label.append(adata_s.obs['condition'][0])\n",
    "\n",
    "\n",
    "adata_sample_emb = sc.AnnData(np.array(sample_data_list)[:,0,:])\n",
    "\n",
    "\n",
    "\n",
    "adata_sample_emb.obs['condition'] = dis_label \n",
    "\n",
    "\n",
    "sc.pp.neighbors(adata_sample_emb, use_rep='X')\n",
    "sc.tl.umap(adata_sample_emb)\n",
    "sc.pl.umap(adata_sample_emb, color='condition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ae7039-6225-45a8-9655-7ae6e31177f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_c_f_old = adata_c_f.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fd3e4f-52af-48fe-b218-406dbd73661f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "adata_c_f = adata_c_f_old[adata_c_f_old.obs['celltype'] == 'Non classical monocytes']\n",
    "\n",
    "\n",
    "attributions_list = []\n",
    "approximation_error_list = []\n",
    "label_list = []\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    for item in adata_c_f.obs['sampleID'].unique():\n",
    "        adata_s = adata_c_f[adata_c_f.obs['sampleID'] == item]\n",
    "        input_data = adata_s.X.toarray().reshape(1,  adata_s.X.shape[0], adata_s.X.shape[1])\n",
    "        baselines = torch.FloatTensor(np.zeros_like(input_data)).to('cuda')\n",
    "        query = torch.FloatTensor(input_data).to('cuda')\n",
    "        attributions, approximation_error = ig.attribute(query,\n",
    "                                                         baselines=baselines,\n",
    "                                                         target=1,\n",
    "                                                         return_convergence_delta=True)\n",
    "        attributions_list.append(attributions.detach().to('cpu'))\n",
    "        approximation_error_list.append(approximation_error.detach().to('cpu'))\n",
    "        label_list.append(adata_s.obs['condition'][0])\n",
    "        del input_data \n",
    "        del baselines\n",
    "        del query\n",
    "else:\n",
    "    for item in adata_c_f.obs['sampleID'].unique():\n",
    "        adata_s = adata_c_f[adata_c_f.obs['sampleID'] == item]\n",
    "        input_data = adata_s.X.toarray().reshape(1,  adata_s.X.shape[0], adata_s.X.shape[1])\n",
    "        baselines = torch.FloatTensor(np.zeros_like(input_data))\n",
    "        query = torch.FloatTensor(input_data)\n",
    "        attributions, approximation_error = ig.attribute(query,\n",
    "                                                         baselines=baselines,\n",
    "                                                         target=1,\n",
    "                                                         return_convergence_delta=True)\n",
    "        attributions_list.append(attributions.detach().to('cpu'))\n",
    "        approximation_error_list.append(approximation_error.detach().to('cpu'))\n",
    "        label_list.append(adata_s.obs['condition'][0])\n",
    "\n",
    "\n",
    "gene_average = []\n",
    "for i,j in zip(attributions_list,label_list):\n",
    "    gene_average.append(i.cpu().numpy().mean(axis=1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mean_set = np.array(gene_average).mean(axis=0)\n",
    "\n",
    "matched_gene = []\n",
    "for i in range(len(adata_c_f.var)):\n",
    "    if adata_c_f.var_names[i] in adata.var_names:\n",
    "        if mean_set[0][i] >0:\n",
    "            matched_gene.append(i)\n",
    "\n",
    "\n",
    "\n",
    "overall_average = []\n",
    "for i,j in zip(attributions_list,label_list):\n",
    "    overall_average.append(i.cpu().numpy()[:,:,matched_gene].mean())\n",
    "\n",
    "scal = sklearn.preprocessing.MinMaxScaler()\n",
    "overall_average = scal.fit_transform(np.array(overall_average).astype('float').reshape(-1,1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "healthy_average = []\n",
    "disease_average = []\n",
    "for i,j in zip(overall_average.T[0],label_list):\n",
    "    if j == 'Mild':\n",
    "        healthy_average.append(i)\n",
    "    else:\n",
    "        disease_average.append(i)\n",
    "        \n",
    "\n",
    "scipy.stats.ranksums(healthy_average, disease_average, alternative='less')\n",
    "df1 = pd.DataFrame({'Mild':healthy_average})\n",
    "df2 = pd.DataFrame({'Severe':disease_average})\n",
    "\n",
    "\n",
    "\n",
    "df = pd.concat([df1, df2])\n",
    "\n",
    "\n",
    "df.boxplot(figsize=(4,4), fontsize=15)\n",
    "plt.ylabel('Attributions')\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
