{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example for model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch\n",
    "from hydra import compose, initialize, initialize_config_dir\n",
    "from omegaconf import OmegaConf\n",
    "import hydra\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import pascient  # your new package\n",
    "sys.modules['cellm'] = pascient\n",
    "\n",
    "\n",
    "def load_model(config_path, checkpoint_path):\n",
    "    \"\"\"\n",
    "    Utility function to load a model from a checkpoint.\n",
    "    \"\"\"\n",
    "\n",
    "    with initialize_config_dir(version_base=None, config_dir=config_path, job_name=\"test_app\"):\n",
    "        cfg = compose(config_name=\"config.yaml\", return_hydra_config=True, \n",
    "                    overrides=[\"data.multiprocessing_context=null\", \"data.batch_size=16\",\"data.sampler_cls._target_=cellm.data.data_samplers.BaseSampler\",\"+data.output_map.return_index=True\"])\n",
    "        print(OmegaConf.to_yaml(cfg))\n",
    "\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    metrics = hydra.utils.instantiate(cfg.get(\"metrics\"))\n",
    "    model = hydra.utils.instantiate(cfg.model, metrics = metrics)\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    model.eval()\n",
    "\n",
    "    cfg.paths.output_dir = \"\"\n",
    "\n",
    "    return model\n",
    "\n",
    "class ForwardModel(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    A wrapper class for the model to handle the forward pass.\n",
    "    If last layer = True, it returns the last layer of the embedding\n",
    "\n",
    "    Output :\n",
    "    - patient embedding\n",
    "    - cell cross embedding\n",
    "    - patient prediction\n",
    "    \"\"\"\n",
    "    def __init__(self, base_model, last_layer = True):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.last_layer = last_layer\n",
    "    def forward(self, x, padding_mask):\n",
    "        #assert x.shape[0] == 1\n",
    "        cell_embds = self.base_model.gene2cell_encoder(x)\n",
    "        cell_cross_embds = self.base_model.cell2cell_encoder(cell_embds, padding_mask = padding_mask)\n",
    "        patient_embds = self.base_model.cell2patient_aggregation.aggregate(data = cell_cross_embds, mask = padding_mask)\n",
    "        patient_embds_2 = self.base_model.patient_encoder(patient_embds)\n",
    "        patient_preds = self.base_model.patient_predictor(patient_embds_2)\n",
    "        if self.last_layer:\n",
    "            return patient_embds_2, cell_cross_embds, patient_preds\n",
    "        else:\n",
    "            return patient_embds, cell_cross_embds, patient_preds\n",
    "\n",
    "\n",
    "def lognormalize(x, padded_mask, target_sum = 1e4):\n",
    "    \"\"\"\n",
    "    Normalize the input tensor using log normalization.\n",
    "    \"\"\"\n",
    "    X = x\n",
    "    pad_mask = padded_mask\n",
    "\n",
    "    counts_per_cell = X.sum(axis=-1) +1e-8\n",
    "    counts_per_cell = counts_per_cell / target_sum\n",
    "\n",
    "    counts_per_cell[~pad_mask] = 1\n",
    "\n",
    "    X_padded_norm = X / counts_per_cell[..., None]\n",
    "\n",
    "    X_padded_out = X_padded_norm.log1p()\n",
    "\n",
    "    return X_padded_out, padded_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hydra:\n",
      "  run:\n",
      "    dir: outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}\n",
      "  sweep:\n",
      "    dir: multirun/${now:%Y-%m-%d}/${now:%H-%M-%S}\n",
      "    subdir: ${hydra.job.num}\n",
      "  launcher:\n",
      "    _target_: hydra._internal.core_plugins.basic_launcher.BasicLauncher\n",
      "  sweeper:\n",
      "    _target_: hydra._internal.core_plugins.basic_sweeper.BasicSweeper\n",
      "    max_batch_size: null\n",
      "    params: null\n",
      "  help:\n",
      "    app_name: ${hydra.job.name}\n",
      "    header: '${hydra.help.app_name} is powered by Hydra.\n",
      "\n",
      "      '\n",
      "    footer: 'Powered by Hydra (https://hydra.cc)\n",
      "\n",
      "      Use --hydra-help to view Hydra specific help\n",
      "\n",
      "      '\n",
      "    template: '${hydra.help.header}\n",
      "\n",
      "      == Configuration groups ==\n",
      "\n",
      "      Compose your configuration from those groups (group=option)\n",
      "\n",
      "\n",
      "      $APP_CONFIG_GROUPS\n",
      "\n",
      "\n",
      "      == Config ==\n",
      "\n",
      "      Override anything in the config (foo.bar=value)\n",
      "\n",
      "\n",
      "      $CONFIG\n",
      "\n",
      "\n",
      "      ${hydra.help.footer}\n",
      "\n",
      "      '\n",
      "  hydra_help:\n",
      "    template: 'Hydra (${hydra.runtime.version})\n",
      "\n",
      "      See https://hydra.cc for more info.\n",
      "\n",
      "\n",
      "      == Flags ==\n",
      "\n",
      "      $FLAGS_HELP\n",
      "\n",
      "\n",
      "      == Configuration groups ==\n",
      "\n",
      "      Compose your configuration from those groups (For example, append hydra/job_logging=disabled\n",
      "      to command line)\n",
      "\n",
      "\n",
      "      $HYDRA_CONFIG_GROUPS\n",
      "\n",
      "\n",
      "      Use ''--cfg hydra'' to Show the Hydra config.\n",
      "\n",
      "      '\n",
      "    hydra_help: ???\n",
      "  hydra_logging:\n",
      "    version: 1\n",
      "    formatters:\n",
      "      simple:\n",
      "        format: '[%(asctime)s][HYDRA] %(message)s'\n",
      "    handlers:\n",
      "      console:\n",
      "        class: logging.StreamHandler\n",
      "        formatter: simple\n",
      "        stream: ext://sys.stdout\n",
      "    root:\n",
      "      level: INFO\n",
      "      handlers:\n",
      "      - console\n",
      "    loggers:\n",
      "      logging_example:\n",
      "        level: DEBUG\n",
      "    disable_existing_loggers: false\n",
      "  job_logging:\n",
      "    version: 1\n",
      "    formatters:\n",
      "      simple:\n",
      "        format: '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'\n",
      "    handlers:\n",
      "      console:\n",
      "        class: logging.StreamHandler\n",
      "        formatter: simple\n",
      "        stream: ext://sys.stdout\n",
      "      file:\n",
      "        class: logging.FileHandler\n",
      "        formatter: simple\n",
      "        filename: ${hydra.runtime.output_dir}/${hydra.job.name}.log\n",
      "    root:\n",
      "      level: INFO\n",
      "      handlers:\n",
      "      - console\n",
      "      - file\n",
      "    disable_existing_loggers: false\n",
      "  env: {}\n",
      "  mode: null\n",
      "  searchpath: []\n",
      "  callbacks: {}\n",
      "  output_subdir: .hydra\n",
      "  overrides:\n",
      "    hydra: []\n",
      "    task:\n",
      "    - data.multiprocessing_context=null\n",
      "    - data.batch_size=16\n",
      "    - data.sampler_cls._target_=cellm.data.data_samplers.BaseSampler\n",
      "    - +data.output_map.return_index=True\n",
      "  job:\n",
      "    name: test_app\n",
      "    chdir: null\n",
      "    override_dirname: +data.output_map.return_index=True,data.batch_size=16,data.multiprocessing_context=null,data.sampler_cls._target_=cellm.data.data_samplers.BaseSampler\n",
      "    id: ???\n",
      "    num: ???\n",
      "    config_name: config.yaml\n",
      "    env_set: {}\n",
      "    env_copy: []\n",
      "    config:\n",
      "      override_dirname:\n",
      "        kv_sep: '='\n",
      "        item_sep: ','\n",
      "        exclude_keys: []\n",
      "  runtime:\n",
      "    version: 1.3.2\n",
      "    version_base: '1.3'\n",
      "    cwd: /homefs/home/debroue1/projects/pascient_github/pascient/pascient/notebooks/paper_figures\n",
      "    config_sources:\n",
      "    - path: hydra.conf\n",
      "      schema: pkg\n",
      "      provider: hydra\n",
      "    - path: /homefs/home/debroue1/projects/pascient_github/resources/multilabel_model/.hydra/\n",
      "      schema: file\n",
      "      provider: main\n",
      "    - path: hydra_plugins.hydra_colorlog.conf\n",
      "      schema: pkg\n",
      "      provider: hydra-colorlog\n",
      "    - path: ''\n",
      "      schema: structured\n",
      "      provider: schema\n",
      "    output_dir: ???\n",
      "    choices:\n",
      "      hydra/env: default\n",
      "      hydra/callbacks: null\n",
      "      hydra/job_logging: default\n",
      "      hydra/hydra_logging: default\n",
      "      hydra/hydra_help: default\n",
      "      hydra/help: default\n",
      "      hydra/sweeper: basic\n",
      "      hydra/launcher: basic\n",
      "      hydra/output: default\n",
      "  verbose: false\n",
      "task_name: train\n",
      "tags:\n",
      "- pascient\n",
      "- multilabel\n",
      "train: true\n",
      "test: false\n",
      "ckpt_path: null\n",
      "seed: 12345\n",
      "experiment_name: pascient-multilabel\n",
      "data:\n",
      "  augmentations: {}\n",
      "  _target_: pascient.data.data_scimilarity.PatientCellsDataModule\n",
      "  cell_tdb_uri: /braid/cellm/tiledb/scimilarity_human_10x_cell_metadata\n",
      "  matrix_tdb_uri: /braid/cellm/tiledb/scimilarity_human_10x_counts\n",
      "  gene_tdb_uri: /braid/cellm/tiledb/scimilarity_human_10x_gene_metadata\n",
      "  gene_order: /braid/cellm/gene_order.tsv\n",
      "  val_studies: null\n",
      "  test_studies: null\n",
      "  label_id_column: disease\n",
      "  study_column: study\n",
      "  sample_column: sample\n",
      "  gene_column: genes\n",
      "  extra_columns:\n",
      "  - tissue\n",
      "  - celltype_id\n",
      "  remove_new_val_labels: false\n",
      "  lognorm: true\n",
      "  batch_size: 16\n",
      "  sample_size: 1500\n",
      "  num_workers: 12\n",
      "  num_genes: 28231\n",
      "  persistent_workers: true\n",
      "  oversampling:\n",
      "  - disease\n",
      "  - tissue\n",
      "  multiprocessing_context: null\n",
      "  sampler_cls:\n",
      "    _target_: cellm.data.data_samplers.BaseSampler\n",
      "    _partial_: true\n",
      "    attributes:\n",
      "    - disease\n",
      "    - tissue\n",
      "    sample_col: study::::sample\n",
      "  output_map:\n",
      "    _target_: pascient.data.batch_mappers.PaSCientDiseaseMapper\n",
      "    pad_size: ${data.sample_size}\n",
      "    sample_labels:\n",
      "    - - study::::sample\n",
      "      - categorical\n",
      "    - - disease\n",
      "      - categorical\n",
      "    - - tissue\n",
      "      - categorical\n",
      "    cell_labels:\n",
      "    - - celltype_id\n",
      "      - categorical\n",
      "    return_ontology: false\n",
      "    disease_dict: ${paths.data_dir}/pascient/disease_loader_overlap9.pickle\n",
      "    return_index: true\n",
      "  cached_db: null\n",
      "  overwrite_cache: false\n",
      "  dataset_cls:\n",
      "    _target_: pascient.data.data_scimilarity.scDatasetAugmented\n",
      "    _partial_: true\n",
      "    n_views_per_sample: 1\n",
      "    overlap_samples: true\n",
      "  dataset_name: pascient_multilabel\n",
      "  val_studies_paths:\n",
      "    val: ${paths.data_dir}/validation_studies/pascient/val_study_commondisease10.json\n",
      "    test: ${paths.data_dir}/validation_studies/pascient/test_study_commondisease10.json\n",
      "model:\n",
      "  gene2cell_encoder:\n",
      "    _target_: pascient.components.basic_models.BasicMLP\n",
      "    input_dim: ${model.num_genes}\n",
      "    hidden_dim: ${model.gene2cell_encoder.output_dim}\n",
      "    output_dim: 1024\n",
      "    n_hidden_layers: -1\n",
      "  patient_encoder:\n",
      "    _target_: pascient.components.basic_models.BasicMLP\n",
      "    input_dim: ${model.gene2cell_encoder.hidden_dim}\n",
      "    hidden_dim: ${eval:'${model.gene2cell_encoder.hidden_dim}//2'}\n",
      "    output_dim: ${eval:'${model.gene2cell_encoder.hidden_dim}//2'}\n",
      "    n_hidden_layers: 0\n",
      "    activation_cls:\n",
      "      _target_: torch.nn.PReLU\n",
      "      _partial_: true\n",
      "    activation_out_cls:\n",
      "      _target_: torch.nn.PReLU\n",
      "      _partial_: true\n",
      "  cell2patient_aggregation:\n",
      "    _target_: pascient.components.aggregators.NonLinearAttnAggregator\n",
      "    attention_model:\n",
      "      _target_: pascient.components.basic_models.BasicMLP\n",
      "      input_dim: ${model.gene2cell_encoder.hidden_dim}\n",
      "      hidden_dim: 1024\n",
      "      output_dim: 1\n",
      "      n_hidden_layers: 0\n",
      "      activation_cls:\n",
      "        _target_: torch.nn.Tanh\n",
      "        _partial_: true\n",
      "  cell2cell_encoder:\n",
      "    _target_: pascient.components.cell_to_cell.CellToCellIdentity\n",
      "  cell2output:\n",
      "    _target_: pascient.components.cell_to_output.CellToOutputNone\n",
      "  patient_predictor:\n",
      "    _target_: pascient.components.basic_models.BasicMLP\n",
      "    input_dim: ${model.patient_encoder.output_dim}\n",
      "    hidden_dim: ${model.patient_predictor.output_dim}\n",
      "    output_dim: 9\n",
      "    n_hidden_layers: -1\n",
      "  losses:\n",
      "    cross_mask_loss:\n",
      "      weight: 0\n",
      "    cell_contrastive_loss:\n",
      "      weight: 0\n",
      "    sample_contrastive_loss:\n",
      "      weight: 0\n",
      "    sample_prediction_loss:\n",
      "      weight: 1\n",
      "      loss_fn:\n",
      "        _target_: pascient.components.losses.CrossEntropyLossViews\n",
      "        _partial_: true\n",
      "        weight:\n",
      "        - 57\n",
      "        - 5\n",
      "        - 268\n",
      "        - 59\n",
      "        - 1443\n",
      "        - 48\n",
      "        - 20\n",
      "        - 11\n",
      "        - 30\n",
      "        label_smoothing: 0.0\n",
      "      labels:\n",
      "      - disease\n",
      "  _target_: pascient.model.sample_predictor.SamplePredictor\n",
      "  optimizer:\n",
      "    _target_: torch.optim.Adam\n",
      "    _partial_: true\n",
      "    lr: 0.0001\n",
      "    weight_decay: 0.0001\n",
      "  scheduler:\n",
      "    _target_: torch.optim.lr_scheduler.ReduceLROnPlateau\n",
      "    _partial_: true\n",
      "    mode: min\n",
      "    factor: 0.1\n",
      "    patience: 20\n",
      "  masking_strategy:\n",
      "    _target_: pascient.components.masking.DummyMasking\n",
      "    mask_p: 0.0\n",
      "  cell_decoder: null\n",
      "  num_genes: ${data.num_genes}\n",
      "  dropout: 0.0\n",
      "  cell_contrastive_strategy: classic\n",
      "  compile: false\n",
      "callbacks:\n",
      "  model_checkpoint:\n",
      "    _target_: lightning.pytorch.callbacks.ModelCheckpoint\n",
      "    dirpath: ${paths.output_dir}/checkpoints\n",
      "    filename: epoch_{epoch:03d}\n",
      "    monitor: val/loss\n",
      "    verbose: false\n",
      "    save_last: true\n",
      "    save_top_k: 4\n",
      "    mode: min\n",
      "    auto_insert_metric_name: false\n",
      "    save_weights_only: false\n",
      "    every_n_train_steps: null\n",
      "    train_time_interval: null\n",
      "    every_n_epochs: null\n",
      "    save_on_train_epoch_end: null\n",
      "  early_stopping:\n",
      "    _target_: lightning.pytorch.callbacks.EarlyStopping\n",
      "    monitor: val/loss\n",
      "    min_delta: 0.0\n",
      "    patience: 100\n",
      "    verbose: false\n",
      "    mode: min\n",
      "    strict: true\n",
      "    check_finite: true\n",
      "    stopping_threshold: null\n",
      "    divergence_threshold: null\n",
      "    check_on_train_epoch_end: null\n",
      "  model_summary:\n",
      "    _target_: lightning.pytorch.callbacks.RichModelSummary\n",
      "    max_depth: -1\n",
      "  rich_progress_bar:\n",
      "    _target_: lightning.pytorch.callbacks.RichProgressBar\n",
      "  lr_monitor:\n",
      "    _target_: lightning.pytorch.callbacks.LearningRateMonitor\n",
      "    logging_interval: epoch\n",
      "    log_momentum: true\n",
      "    log_weight_decay: true\n",
      "logger:\n",
      "  wandb:\n",
      "    _target_: lightning.pytorch.loggers.wandb.WandbLogger\n",
      "    name: ${experiment_name}\n",
      "    save_dir: ${paths.output_dir}\n",
      "    offline: false\n",
      "    id: null\n",
      "    anonymous: null\n",
      "    project: patient_embeds\n",
      "    log_model: false\n",
      "    prefix: ''\n",
      "    group: ''\n",
      "    tags: ${tags}\n",
      "    job_type: ''\n",
      "trainer:\n",
      "  _target_: lightning.pytorch.trainer.Trainer\n",
      "  default_root_dir: ${paths.output_dir}\n",
      "  min_epochs: 1\n",
      "  max_epochs: 4\n",
      "  accelerator: gpu\n",
      "  devices: 1\n",
      "  strategy: auto\n",
      "  check_val_every_n_epoch: 1\n",
      "  deterministic: false\n",
      "  log_every_n_steps: 5\n",
      "paths:\n",
      "  root_dir: ${oc.env:PROJECT_ROOT}\n",
      "  data_dir: ${paths.root_dir}/data/\n",
      "  log_dir: ${paths.root_dir}/logs/\n",
      "  output_dir: ${hydra:runtime.output_dir}\n",
      "  work_dir: ${hydra:runtime.cwd}\n",
      "extras:\n",
      "  ignore_warnings: false\n",
      "  enforce_tags: true\n",
      "  print_config: true\n",
      "metrics:\n",
      "  sample_accuracy:\n",
      "    _target_: pascient.components.metrics.AccuracyMetric\n",
      "    name: sample_accuracy\n",
      "    labels: ${model.losses.sample_prediction_loss.labels}\n",
      "    num_classes: ${model.patient_predictor.output_dim}\n",
      "    task: multiclass\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2953474/3705933639.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path)\n",
      "/homefs/home/debroue1/miniforge3/envs/pascient_test/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'gene2cell_encoder' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['gene2cell_encoder'])`.\n",
      "/homefs/home/debroue1/miniforge3/envs/pascient_test/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'cell2cell_encoder' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['cell2cell_encoder'])`.\n",
      "/homefs/home/debroue1/miniforge3/envs/pascient_test/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'cell2patient_aggregation' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['cell2patient_aggregation'])`.\n",
      "/homefs/home/debroue1/miniforge3/envs/pascient_test/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'patient_encoder' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['patient_encoder'])`.\n",
      "/homefs/home/debroue1/miniforge3/envs/pascient_test/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'patient_predictor' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['patient_predictor'])`.\n"
     ]
    }
   ],
   "source": [
    "# Add path to model\n",
    "resources_path = \"/homefs/home/debroue1/projects/pascient_github/resources/multilabel_model\"\n",
    "config_path = f\"{resources_path}/.hydra/\"\n",
    "checkpoint_path = f\"{resources_path}/checkpoints/pascient.ckpt\"\n",
    "model = load_model(config_path, checkpoint_path)\n",
    "model_fwd = ForwardModel(model, last_layer = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running inference on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellm.data.data_structures import SampleBatch\n",
    "\n",
    "# Example for orginal count data\n",
    "# Tensor size should be Samples x 1 x Cells x Genes\n",
    "x = 50 + torch.randn(16,1,1000,28231)\n",
    "# Padding mask is True if cell is observed and False if cell is masked\n",
    "padding_mask = torch.ones(16,1,1000).bool()\n",
    "\n",
    "x, padding_mask = lognormalize(x, padding_mask)\n",
    "sample_embeds, cell_embds, sample_preds = model_fwd(x, padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 512])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pascient_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
