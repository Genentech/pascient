{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example for model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch\n",
    "from hydra import compose, initialize, initialize_config_dir\n",
    "from omegaconf import OmegaConf\n",
    "import hydra\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_model(config_path, checkpoint_path):\n",
    "    \"\"\"\n",
    "    Utility function to load a model from a checkpoint.\n",
    "    \"\"\"\n",
    "\n",
    "    with initialize_config_dir(version_base=None, config_dir=config_path, job_name=\"test_app\"):\n",
    "        cfg = compose(config_name=\"config.yaml\", return_hydra_config=True, \n",
    "                    overrides=[\"data.multiprocessing_context=null\", \"data.batch_size=16\",\"data.sampler_cls._target_=cellm.data.data_samplers.BaseSampler\",\"+data.output_map.return_index=True\"])\n",
    "        print(OmegaConf.to_yaml(cfg))\n",
    "\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    metrics = hydra.utils.instantiate(cfg.get(\"metrics\"))\n",
    "    model = hydra.utils.instantiate(cfg.model, metrics = metrics)\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    model.eval()\n",
    "\n",
    "    cfg.paths.output_dir = \"\"\n",
    "\n",
    "    return model\n",
    "\n",
    "class ForwardModel(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    A wrapper class for the model to handle the forward pass.\n",
    "    If last layer = True, it returns the last layer of the embedding\n",
    "\n",
    "    Output :\n",
    "    - patient embedding\n",
    "    - cell cross embedding\n",
    "    - patient prediction\n",
    "    \"\"\"\n",
    "    def __init__(self, base_model, last_layer = True):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.last_layer = last_layer\n",
    "    def forward(self, x, padding_mask):\n",
    "        #assert x.shape[0] == 1\n",
    "        cell_embds = self.base_model.gene2cell_encoder(x)\n",
    "        cell_cross_embds = self.base_model.cell2cell_encoder(cell_embds, padding_mask = padding_mask)\n",
    "        patient_embds = self.base_model.cell2patient_aggregation.aggregate(data = cell_cross_embds, mask = padding_mask)\n",
    "        patient_embds_2 = self.base_model.patient_encoder(patient_embds)\n",
    "        patient_preds = self.base_model.patient_predictor(patient_embds_2)\n",
    "        if self.last_layer:\n",
    "            return patient_embds_2, cell_cross_embds, patient_preds\n",
    "        else:\n",
    "            return patient_embds, cell_cross_embds, patient_preds\n",
    "\n",
    "\n",
    "def lognormalize(x, padded_mask, target_sum = 1e4):\n",
    "    \"\"\"\n",
    "    Normalize the input tensor using log normalization.\n",
    "    \"\"\"\n",
    "    X = x\n",
    "    pad_mask = padded_mask\n",
    "\n",
    "    counts_per_cell = X.sum(axis=-1) +1e-8\n",
    "    counts_per_cell = counts_per_cell / target_sum\n",
    "\n",
    "    counts_per_cell[~pad_mask] = 1\n",
    "\n",
    "    X_padded_norm = X / counts_per_cell[..., None]\n",
    "\n",
    "    X_padded_out = X_padded_norm.log1p()\n",
    "\n",
    "    return X_padded_out, padded_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hydra:\n",
      "  run:\n",
      "    dir: outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}\n",
      "  sweep:\n",
      "    dir: multirun/${now:%Y-%m-%d}/${now:%H-%M-%S}\n",
      "    subdir: ${hydra.job.num}\n",
      "  launcher:\n",
      "    _target_: hydra._internal.core_plugins.basic_launcher.BasicLauncher\n",
      "  sweeper:\n",
      "    _target_: hydra._internal.core_plugins.basic_sweeper.BasicSweeper\n",
      "    max_batch_size: null\n",
      "    params: null\n",
      "  help:\n",
      "    app_name: ${hydra.job.name}\n",
      "    header: '${hydra.help.app_name} is powered by Hydra.\n",
      "\n",
      "      '\n",
      "    footer: 'Powered by Hydra (https://hydra.cc)\n",
      "\n",
      "      Use --hydra-help to view Hydra specific help\n",
      "\n",
      "      '\n",
      "    template: '${hydra.help.header}\n",
      "\n",
      "      == Configuration groups ==\n",
      "\n",
      "      Compose your configuration from those groups (group=option)\n",
      "\n",
      "\n",
      "      $APP_CONFIG_GROUPS\n",
      "\n",
      "\n",
      "      == Config ==\n",
      "\n",
      "      Override anything in the config (foo.bar=value)\n",
      "\n",
      "\n",
      "      $CONFIG\n",
      "\n",
      "\n",
      "      ${hydra.help.footer}\n",
      "\n",
      "      '\n",
      "  hydra_help:\n",
      "    template: 'Hydra (${hydra.runtime.version})\n",
      "\n",
      "      See https://hydra.cc for more info.\n",
      "\n",
      "\n",
      "      == Flags ==\n",
      "\n",
      "      $FLAGS_HELP\n",
      "\n",
      "\n",
      "      == Configuration groups ==\n",
      "\n",
      "      Compose your configuration from those groups (For example, append hydra/job_logging=disabled\n",
      "      to command line)\n",
      "\n",
      "\n",
      "      $HYDRA_CONFIG_GROUPS\n",
      "\n",
      "\n",
      "      Use ''--cfg hydra'' to Show the Hydra config.\n",
      "\n",
      "      '\n",
      "    hydra_help: ???\n",
      "  hydra_logging:\n",
      "    version: 1\n",
      "    formatters:\n",
      "      simple:\n",
      "        format: '[%(asctime)s][HYDRA] %(message)s'\n",
      "    handlers:\n",
      "      console:\n",
      "        class: logging.StreamHandler\n",
      "        formatter: simple\n",
      "        stream: ext://sys.stdout\n",
      "    root:\n",
      "      level: INFO\n",
      "      handlers:\n",
      "      - console\n",
      "    loggers:\n",
      "      logging_example:\n",
      "        level: DEBUG\n",
      "    disable_existing_loggers: false\n",
      "  job_logging:\n",
      "    version: 1\n",
      "    formatters:\n",
      "      simple:\n",
      "        format: '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'\n",
      "    handlers:\n",
      "      console:\n",
      "        class: logging.StreamHandler\n",
      "        formatter: simple\n",
      "        stream: ext://sys.stdout\n",
      "      file:\n",
      "        class: logging.FileHandler\n",
      "        formatter: simple\n",
      "        filename: ${hydra.runtime.output_dir}/${hydra.job.name}.log\n",
      "    root:\n",
      "      level: INFO\n",
      "      handlers:\n",
      "      - console\n",
      "      - file\n",
      "    disable_existing_loggers: false\n",
      "  env: {}\n",
      "  mode: null\n",
      "  searchpath: []\n",
      "  callbacks: {}\n",
      "  output_subdir: .hydra\n",
      "  overrides:\n",
      "    hydra: []\n",
      "    task:\n",
      "    - data.multiprocessing_context=null\n",
      "    - data.batch_size=16\n",
      "    - data.sampler_cls._target_=cellm.data.data_samplers.BaseSampler\n",
      "    - +data.output_map.return_index=True\n",
      "  job:\n",
      "    name: test_app\n",
      "    chdir: null\n",
      "    override_dirname: +data.output_map.return_index=True,data.batch_size=16,data.multiprocessing_context=null,data.sampler_cls._target_=cellm.data.data_samplers.BaseSampler\n",
      "    id: ???\n",
      "    num: ???\n",
      "    config_name: config.yaml\n",
      "    env_set: {}\n",
      "    env_copy: []\n",
      "    config:\n",
      "      override_dirname:\n",
      "        kv_sep: '='\n",
      "        item_sep: ','\n",
      "        exclude_keys: []\n",
      "  runtime:\n",
      "    version: 1.3.2\n",
      "    version_base: '1.3'\n",
      "    cwd: /homefs/home/debroue1/projects/cellm/cellm/notebooks/paper_figures\n",
      "    config_sources:\n",
      "    - path: hydra.conf\n",
      "      schema: pkg\n",
      "      provider: hydra\n",
      "    - path: /homefs/home/debroue1/projects/cellm/logs/train/runs/2025-02-09_22-25-15/.hydra/\n",
      "      schema: file\n",
      "      provider: main\n",
      "    - path: hydra_plugins.hydra_colorlog.conf\n",
      "      schema: pkg\n",
      "      provider: hydra-colorlog\n",
      "    - path: ''\n",
      "      schema: structured\n",
      "      provider: schema\n",
      "    output_dir: ???\n",
      "    choices:\n",
      "      hydra/env: default\n",
      "      hydra/callbacks: null\n",
      "      hydra/job_logging: default\n",
      "      hydra/hydra_logging: default\n",
      "      hydra/hydra_help: default\n",
      "      hydra/help: default\n",
      "      hydra/sweeper: basic\n",
      "      hydra/launcher: basic\n",
      "      hydra/output: default\n",
      "  verbose: false\n",
      "task_name: train\n",
      "tags:\n",
      "- pascient\n",
      "- multilabel\n",
      "train: true\n",
      "test: false\n",
      "ckpt_path: null\n",
      "seed: 12345\n",
      "experiment_name: pascient-multilabel\n",
      "data:\n",
      "  augmentations: {}\n",
      "  _target_: cellm.data.data_scimilarity.PatientCellsDataModule\n",
      "  cell_tdb_uri: /braid/cellm/tiledb/scimilarity_human_10x_cell_metadata\n",
      "  matrix_tdb_uri: /braid/cellm/tiledb/scimilarity_human_10x_counts\n",
      "  gene_tdb_uri: /braid/cellm/tiledb/scimilarity_human_10x_gene_metadata\n",
      "  gene_order: /braid/cellm/gene_order.tsv\n",
      "  val_studies: null\n",
      "  test_studies: null\n",
      "  label_id_column: disease\n",
      "  study_column: study\n",
      "  sample_column: sample\n",
      "  gene_column: genes\n",
      "  extra_columns:\n",
      "  - tissue\n",
      "  - celltype_id\n",
      "  remove_new_val_labels: false\n",
      "  lognorm: true\n",
      "  batch_size: 16\n",
      "  sample_size: 1500\n",
      "  num_workers: 12\n",
      "  num_genes: 28231\n",
      "  persistent_workers: true\n",
      "  oversampling:\n",
      "  - disease\n",
      "  - tissue\n",
      "  multiprocessing_context: null\n",
      "  sampler_cls:\n",
      "    _target_: cellm.data.data_samplers.BaseSampler\n",
      "    _partial_: true\n",
      "    attributes:\n",
      "    - disease\n",
      "    - tissue\n",
      "    sample_col: study::::sample\n",
      "  output_map:\n",
      "    _target_: cellm.data.batch_mappers.PaSCientDiseaseMapper\n",
      "    pad_size: ${data.sample_size}\n",
      "    sample_labels:\n",
      "    - - study::::sample\n",
      "      - categorical\n",
      "    - - disease\n",
      "      - categorical\n",
      "    - - tissue\n",
      "      - categorical\n",
      "    cell_labels:\n",
      "    - - celltype_id\n",
      "      - categorical\n",
      "    return_ontology: false\n",
      "    disease_dict: ${paths.data_dir}/pascient/disease_loader_overlap9.pickle\n",
      "    return_index: true\n",
      "  cached_db: null\n",
      "  overwrite_cache: false\n",
      "  dataset_cls:\n",
      "    _target_: cellm.data.data_scimilarity.scDatasetAugmented\n",
      "    _partial_: true\n",
      "    n_views_per_sample: 1\n",
      "    overlap_samples: true\n",
      "  dataset_name: pascient_multilabel\n",
      "  val_studies_paths:\n",
      "    val: ${paths.data_dir}/validation_studies/pascient/val_study_commondisease10.json\n",
      "    test: ${paths.data_dir}/validation_studies/pascient/test_study_commondisease10.json\n",
      "model:\n",
      "  gene2cell_encoder:\n",
      "    _target_: cellm.components.basic_models.BasicMLP\n",
      "    input_dim: ${model.num_genes}\n",
      "    hidden_dim: ${model.gene2cell_encoder.output_dim}\n",
      "    output_dim: 1024\n",
      "    n_hidden_layers: -1\n",
      "  patient_encoder:\n",
      "    _target_: cellm.components.basic_models.BasicMLP\n",
      "    input_dim: ${model.gene2cell_encoder.hidden_dim}\n",
      "    hidden_dim: ${eval:'${model.gene2cell_encoder.hidden_dim}//2'}\n",
      "    output_dim: ${eval:'${model.gene2cell_encoder.hidden_dim}//2'}\n",
      "    n_hidden_layers: 0\n",
      "    activation_cls:\n",
      "      _target_: torch.nn.PReLU\n",
      "      _partial_: true\n",
      "    activation_out_cls:\n",
      "      _target_: torch.nn.PReLU\n",
      "      _partial_: true\n",
      "  cell2patient_aggregation:\n",
      "    _target_: cellm.components.aggregators.NonLinearAttnAggregator\n",
      "    attention_model:\n",
      "      _target_: cellm.components.basic_models.BasicMLP\n",
      "      input_dim: ${model.gene2cell_encoder.hidden_dim}\n",
      "      hidden_dim: 1024\n",
      "      output_dim: 1\n",
      "      n_hidden_layers: 0\n",
      "      activation_cls:\n",
      "        _target_: torch.nn.Tanh\n",
      "        _partial_: true\n",
      "  cell2cell_encoder:\n",
      "    _target_: cellm.components.cell_to_cell.CellToCellIdentity\n",
      "  cell2output:\n",
      "    _target_: cellm.components.cell_to_output.CellToOutputNone\n",
      "  patient_predictor:\n",
      "    _target_: cellm.components.basic_models.BasicMLP\n",
      "    input_dim: ${model.patient_encoder.output_dim}\n",
      "    hidden_dim: ${model.patient_predictor.output_dim}\n",
      "    output_dim: 9\n",
      "    n_hidden_layers: -1\n",
      "  losses:\n",
      "    cross_mask_loss:\n",
      "      weight: 0\n",
      "    cell_contrastive_loss:\n",
      "      weight: 0\n",
      "    sample_contrastive_loss:\n",
      "      weight: 0\n",
      "    sample_prediction_loss:\n",
      "      weight: 1\n",
      "      loss_fn:\n",
      "        _target_: cellm.components.losses.CrossEntropyLossViews\n",
      "        _partial_: true\n",
      "        weight:\n",
      "        - 57\n",
      "        - 5\n",
      "        - 268\n",
      "        - 59\n",
      "        - 1443\n",
      "        - 48\n",
      "        - 20\n",
      "        - 11\n",
      "        - 30\n",
      "        label_smoothing: 0.0\n",
      "      labels:\n",
      "      - disease\n",
      "  _target_: cellm.model.sample_predictor.SamplePredictor\n",
      "  optimizer:\n",
      "    _target_: torch.optim.Adam\n",
      "    _partial_: true\n",
      "    lr: 0.0001\n",
      "    weight_decay: 0.0001\n",
      "  scheduler:\n",
      "    _target_: torch.optim.lr_scheduler.ReduceLROnPlateau\n",
      "    _partial_: true\n",
      "    mode: min\n",
      "    factor: 0.1\n",
      "    patience: 20\n",
      "  masking_strategy:\n",
      "    _target_: cellm.components.masking.DummyMasking\n",
      "    mask_p: 0.0\n",
      "  cell_decoder: null\n",
      "  num_genes: ${data.num_genes}\n",
      "  dropout: 0.0\n",
      "  cell_contrastive_strategy: classic\n",
      "  compile: false\n",
      "callbacks:\n",
      "  model_checkpoint:\n",
      "    _target_: lightning.pytorch.callbacks.ModelCheckpoint\n",
      "    dirpath: ${paths.output_dir}/checkpoints\n",
      "    filename: epoch_{epoch:03d}\n",
      "    monitor: val/loss\n",
      "    verbose: false\n",
      "    save_last: true\n",
      "    save_top_k: 4\n",
      "    mode: min\n",
      "    auto_insert_metric_name: false\n",
      "    save_weights_only: false\n",
      "    every_n_train_steps: null\n",
      "    train_time_interval: null\n",
      "    every_n_epochs: null\n",
      "    save_on_train_epoch_end: null\n",
      "  early_stopping:\n",
      "    _target_: lightning.pytorch.callbacks.EarlyStopping\n",
      "    monitor: val/loss\n",
      "    min_delta: 0.0\n",
      "    patience: 100\n",
      "    verbose: false\n",
      "    mode: min\n",
      "    strict: true\n",
      "    check_finite: true\n",
      "    stopping_threshold: null\n",
      "    divergence_threshold: null\n",
      "    check_on_train_epoch_end: null\n",
      "  model_summary:\n",
      "    _target_: lightning.pytorch.callbacks.RichModelSummary\n",
      "    max_depth: -1\n",
      "  rich_progress_bar:\n",
      "    _target_: lightning.pytorch.callbacks.RichProgressBar\n",
      "  lr_monitor:\n",
      "    _target_: lightning.pytorch.callbacks.LearningRateMonitor\n",
      "    logging_interval: epoch\n",
      "    log_momentum: true\n",
      "    log_weight_decay: true\n",
      "logger:\n",
      "  wandb:\n",
      "    _target_: lightning.pytorch.loggers.wandb.WandbLogger\n",
      "    name: ${experiment_name}\n",
      "    save_dir: ${paths.output_dir}\n",
      "    offline: false\n",
      "    id: null\n",
      "    anonymous: null\n",
      "    project: patient_embeds\n",
      "    log_model: false\n",
      "    prefix: ''\n",
      "    group: ''\n",
      "    tags: ${tags}\n",
      "    job_type: ''\n",
      "trainer:\n",
      "  _target_: lightning.pytorch.trainer.Trainer\n",
      "  default_root_dir: ${paths.output_dir}\n",
      "  min_epochs: 1\n",
      "  max_epochs: 4\n",
      "  accelerator: gpu\n",
      "  devices: 1\n",
      "  strategy: auto\n",
      "  check_val_every_n_epoch: 1\n",
      "  deterministic: false\n",
      "  log_every_n_steps: 5\n",
      "paths:\n",
      "  root_dir: ${oc.env:PROJECT_ROOT}\n",
      "  data_dir: ${paths.root_dir}/data/\n",
      "  log_dir: ${paths.root_dir}/logs/\n",
      "  output_dir: ${hydra:runtime.output_dir}\n",
      "  work_dir: ${hydra:runtime.cwd}\n",
      "extras:\n",
      "  ignore_warnings: false\n",
      "  enforce_tags: true\n",
      "  print_config: true\n",
      "metrics:\n",
      "  sample_accuracy:\n",
      "    _target_: cellm.components.metrics.AccuracyMetric\n",
      "    name: sample_accuracy\n",
      "    labels: ${model.losses.sample_prediction_loss.labels}\n",
      "    num_classes: ${model.patient_predictor.output_dim}\n",
      "    task: multiclass\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3028542/3133030091.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path)\n",
      "/homefs/home/debroue1/miniforge3/envs/cellm/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'gene2cell_encoder' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['gene2cell_encoder'])`.\n",
      "/homefs/home/debroue1/miniforge3/envs/cellm/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'cell2cell_encoder' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['cell2cell_encoder'])`.\n",
      "/homefs/home/debroue1/miniforge3/envs/cellm/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'cell2patient_aggregation' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['cell2patient_aggregation'])`.\n",
      "/homefs/home/debroue1/miniforge3/envs/cellm/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'patient_encoder' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['patient_encoder'])`.\n",
      "/homefs/home/debroue1/miniforge3/envs/cellm/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'patient_predictor' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['patient_predictor'])`.\n"
     ]
    }
   ],
   "source": [
    "run_name = \"2025-02-09_22-25-15\"\n",
    "model_name = \"epoch_002\" \n",
    "config_path = f\"/homefs/home/debroue1/projects/cellm/logs/train/runs/{run_name}/.hydra/\"\n",
    "checkpoint_path = f\"/homefs/home/debroue1/projects/cellm/logs/train/runs/{run_name}/checkpoints/{model_name}.ckpt\"\n",
    "model = load_model(config_path, checkpoint_path)\n",
    "model_fwd = ForwardModel(model, last_layer = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellm.data.data_structures import SampleBatch\n",
    "\n",
    "\n",
    "# Example for orginal count data\n",
    "# Tensor size should be Samples x 1 x Cells x Genes\n",
    "x = 50 + torch.randn(16,1,1000,28231)\n",
    "# Padding mask is True if cell is observed and False if cell is masked\n",
    "padding_mask = torch.ones(16,1,1000).bool()\n",
    "\n",
    "x, padding_mask = lognormalize(x, padding_mask)\n",
    "embeds = model_fwd(x, padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.8152, -0.5030,  2.2511,  ..., -0.4717, -1.4045,  0.2516]],\n",
       " \n",
       "         [[-0.8150, -0.5032,  2.2534,  ..., -0.4715, -1.4041,  0.2485]],\n",
       " \n",
       "         [[-0.8152, -0.5028,  2.2525,  ..., -0.4714, -1.4039,  0.2510]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-0.8151, -0.5028,  2.2508,  ..., -0.4715, -1.4038,  0.2540]],\n",
       " \n",
       "         [[-0.8155, -0.5030,  2.2523,  ..., -0.4718, -1.4046,  0.2520]],\n",
       " \n",
       "         [[-0.8153, -0.5032,  2.2524,  ..., -0.4716, -1.4041,  0.2526]]],\n",
       "        grad_fn=<PreluKernelBackward0>),\n",
       " tensor([[[[-3.4786,  1.5765,  1.3317,  ...,  1.4100,  2.8394, -2.6609],\n",
       "           [-3.5124,  1.5820,  1.3329,  ...,  1.4465,  2.8304, -2.6920],\n",
       "           [-3.5021,  1.6246,  1.3763,  ...,  1.4691,  2.8533, -2.6118],\n",
       "           ...,\n",
       "           [-3.4855,  1.5913,  1.3168,  ...,  1.4305,  2.8709, -2.7046],\n",
       "           [-3.4916,  1.5983,  1.2849,  ...,  1.4268,  2.8336, -2.7094],\n",
       "           [-3.5350,  1.5697,  1.2935,  ...,  1.3962,  2.8940, -2.6702]]],\n",
       " \n",
       " \n",
       "         [[[-3.5054,  1.5711,  1.3532,  ...,  1.4286,  2.8840, -2.6816],\n",
       "           [-3.5249,  1.5733,  1.3184,  ...,  1.4359,  2.9270, -2.7160],\n",
       "           [-3.5073,  1.5461,  1.3474,  ...,  1.4262,  2.8397, -2.6300],\n",
       "           ...,\n",
       "           [-3.5060,  1.6115,  1.3162,  ...,  1.4332,  2.7824, -2.7299],\n",
       "           [-3.4585,  1.5775,  1.3287,  ...,  1.3827,  2.8792, -2.6842],\n",
       "           [-3.5093,  1.5397,  1.3292,  ...,  1.4096,  2.8888, -2.6831]]],\n",
       " \n",
       " \n",
       "         [[[-3.5043,  1.6122,  1.2986,  ...,  1.3994,  2.8640, -2.6958],\n",
       "           [-3.4963,  1.5618,  1.3641,  ...,  1.4109,  2.8898, -2.6739],\n",
       "           [-3.4801,  1.5677,  1.3797,  ...,  1.4413,  2.8480, -2.6759],\n",
       "           ...,\n",
       "           [-3.4851,  1.5602,  1.4032,  ...,  1.4091,  2.9196, -2.6820],\n",
       "           [-3.5013,  1.5861,  1.3666,  ...,  1.4725,  2.8119, -2.6948],\n",
       "           [-3.4933,  1.5892,  1.4242,  ...,  1.4145,  2.8869, -2.7071]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-3.4877,  1.5747,  1.3354,  ...,  1.4335,  2.8692, -2.6732],\n",
       "           [-3.5039,  1.5604,  1.2738,  ...,  1.4574,  2.8535, -2.6914],\n",
       "           [-3.5271,  1.6044,  1.3411,  ...,  1.4255,  2.9156, -2.6597],\n",
       "           ...,\n",
       "           [-3.4989,  1.5366,  1.3811,  ...,  1.3901,  2.8622, -2.7327],\n",
       "           [-3.5209,  1.6077,  1.2736,  ...,  1.4381,  2.8527, -2.7182],\n",
       "           [-3.4644,  1.5702,  1.3885,  ...,  1.3786,  2.8762, -2.7172]]],\n",
       " \n",
       " \n",
       "         [[[-3.5028,  1.6139,  1.3385,  ...,  1.4110,  2.8591, -2.7326],\n",
       "           [-3.5114,  1.5918,  1.3423,  ...,  1.4638,  2.8646, -2.6781],\n",
       "           [-3.4964,  1.5643,  1.4254,  ...,  1.4173,  2.8779, -2.6730],\n",
       "           ...,\n",
       "           [-3.4890,  1.5977,  1.3314,  ...,  1.3988,  2.8593, -2.6727],\n",
       "           [-3.4771,  1.6240,  1.3288,  ...,  1.3872,  2.8784, -2.7178],\n",
       "           [-3.4968,  1.5692,  1.3505,  ...,  1.3974,  2.8272, -2.6969]]],\n",
       " \n",
       " \n",
       "         [[[-3.5104,  1.5919,  1.3209,  ...,  1.4490,  2.8600, -2.6657],\n",
       "           [-3.4791,  1.5808,  1.3662,  ...,  1.4381,  2.9090, -2.6463],\n",
       "           [-3.5028,  1.5579,  1.3378,  ...,  1.3875,  2.8692, -2.7304],\n",
       "           ...,\n",
       "           [-3.5041,  1.5650,  1.3460,  ...,  1.4221,  2.8598, -2.6944],\n",
       "           [-3.5158,  1.6247,  1.2953,  ...,  1.4691,  2.8926, -2.6352],\n",
       "           [-3.5360,  1.5801,  1.2915,  ...,  1.4121,  2.7941, -2.6618]]]],\n",
       "        grad_fn=<ViewBackward0>),\n",
       " tensor([[[  1.8605,  -0.0400,   5.3445,  -8.3588,  27.9407, -14.5531, -18.7017,\n",
       "            -8.1167, -10.0880]],\n",
       " \n",
       "         [[  1.8615,  -0.0399,   5.3311,  -8.3484,  27.9409, -14.5530, -18.7036,\n",
       "            -8.1120, -10.0873]],\n",
       " \n",
       "         [[  1.8670,  -0.0416,   5.3442,  -8.3528,  27.9295, -14.5486, -18.6955,\n",
       "            -8.1184, -10.0868]],\n",
       " \n",
       "         [[  1.8667,  -0.0423,   5.3443,  -8.3535,  27.9293, -14.5449, -18.6941,\n",
       "            -8.1184, -10.0897]],\n",
       " \n",
       "         [[  1.8654,  -0.0373,   5.3501,  -8.3591,  27.9286, -14.5506, -18.6950,\n",
       "            -8.1166, -10.0897]],\n",
       " \n",
       "         [[  1.8681,  -0.0436,   5.3411,  -8.3504,  27.9285, -14.5453, -18.6952,\n",
       "            -8.1173, -10.0868]],\n",
       " \n",
       "         [[  1.8659,  -0.0426,   5.3396,  -8.3551,  27.9315, -14.5462, -18.6972,\n",
       "            -8.1141, -10.0851]],\n",
       " \n",
       "         [[  1.8647,  -0.0399,   5.3408,  -8.3586,  27.9431, -14.5490, -18.7060,\n",
       "            -8.1193, -10.0900]],\n",
       " \n",
       "         [[  1.8646,  -0.0426,   5.3451,  -8.3548,  27.9301, -14.5462, -18.6955,\n",
       "            -8.1168, -10.0872]],\n",
       " \n",
       "         [[  1.8635,  -0.0353,   5.3575,  -8.3624,  27.9276, -14.5564, -18.6933,\n",
       "            -8.1156, -10.0900]],\n",
       " \n",
       "         [[  1.8590,  -0.0410,   5.3316,  -8.3537,  27.9542, -14.5547, -18.7103,\n",
       "            -8.1176, -10.0894]],\n",
       " \n",
       "         [[  1.8663,  -0.0411,   5.3341,  -8.3504,  27.9316, -14.5442, -18.6958,\n",
       "            -8.1160, -10.0870]],\n",
       " \n",
       "         [[  1.8685,  -0.0392,   5.3470,  -8.3541,  27.9190, -14.5480, -18.6905,\n",
       "            -8.1123, -10.0854]],\n",
       " \n",
       "         [[  1.8730,  -0.0383,   5.3579,  -8.3590,  27.9170, -14.5490, -18.6881,\n",
       "            -8.1194, -10.0883]],\n",
       " \n",
       "         [[  1.8619,  -0.0413,   5.3495,  -8.3571,  27.9450, -14.5567, -18.7065,\n",
       "            -8.1209, -10.0914]],\n",
       " \n",
       "         [[  1.8631,  -0.0376,   5.3489,  -8.3550,  27.9330, -14.5567, -18.6980,\n",
       "            -8.1165, -10.0889]]], grad_fn=<ViewBackward0>))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cellm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
